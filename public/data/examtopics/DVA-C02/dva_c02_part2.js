var DVA_C02_Part2 = 
{
    "msg": "Quiz Questions",
    "data": [{"question_id": "#ec03b654-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A company is developing a new online game that will run on top of Amazon ECS. Four distinct Amazon ECS services will be part of the architecture, each requiring specific permissions to various AWS services. The company wants to optimize the use of the underlying Amazon EC2 instances by bin packing the containers based on memory reservation. Which configuration would allow the Development team to meet these requirements MOST securely?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03b654-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03b654-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Create a new Identity and Access Management (IAM) instance profile containing the required permissions for the various ECS services, then associate that instance role with the underlying EC2 instances.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create four distinct IAM roles, each containing the required permissions for the associated ECS service, then configure each ECS service to reference the associated IAM role.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create four distinct IAM roles, each containing the required permissions for the associated ECS service, then, create an IAM group and configure the ECS cluster to reference that group.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Create four distinct IAM roles, each containing the required permissions for the associated ECS service, then configure each ECS task definition to referen\u0441e the associated IAM role.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03b7d0-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer must re-implement the business logic for an order fulfilment system. The business logic has to make requests to multiple vendors to decide where to purchase an item. The whole process can take up to a week to complete. What is the MOST efficient and SIMPLEST way to implement a system that meets these requirements?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: D</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03b7d0-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03b7d0-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Use AWS Step Functions to execute parallel Lambda functions, and join the results.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create an AWS SQS for each vendor, poll the queue from a worker instance, and joint the results.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use AWS Lambda to asynchronously call a Lambda function for each vendor, and join the results.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use Amazon CloudWatch Events to orchestrate the Lambda functions.<br></p>", "correct": true, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03b924-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>What best practice should first be applied to address this issue?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: B</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03b924-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03b924-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Contact AWS Support for a limit increase.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use the AWS CLI to get the metrics.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Analyze the applications and remove the API call.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Retry the call with exponential backoff.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03ba6e-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer is receiving HTTP 400: ThrottlingException errors intermittently when calling the Amazon CloudWatch API. When a call fails, no data is retrieved. Which techniques will work? (Choose TWO)</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: D,E</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03ba6e-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03ba6e-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Define a Swagger file. Use AWS Elastic Beanstalk to deploy the Swagger file.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Define a Swagger file. Use AWS CodeDeploy to deploy the Swagger file.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Deploy a SAM template with an inline Swagger definition.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Define a Swagger file. Deploy a SAM template that references the Swagger file.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Define an inline Swagger definition in a Lambda function. Invoke the Lambda function.<br></p>", "correct": true, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03bcee-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>An application is real-time processing millions of events that are received through an API. What service could be used to allow multiple consumers to process the data concurrently and MOST cost-effectively?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: D</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03bcee-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03bcee-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Amazon SNS with fanout to an SQS queue for each application.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Amazon SNS with fanout to an SQS FIFO (first-in, first-out) queue for each application.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Amazon Kinesis Firehouse.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Amazon Kinesis Streams.<br></p>", "correct": true, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03bfc8-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>Where should the appspec.yml file be placed in order for AWS CodeDeploy to work?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03bfc8-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03bfc8-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>In the root of the application source code directory structure.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>In the bin folder along with all the complied code.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>In an S3 bucket.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>In the same folder as the application configuration files.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03c1c6-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>An application will ingest data at a very high throughput from many sources and must store the data in an Amazon S3 bucket. Which service would BEST accomplish this task?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03c1c6-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03c1c6-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Amazon Kinesis Firehose.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Amazon S3 Acceleration Transfer.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Amazon SQS.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Amazon SNS.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03c37e-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer is creating a Lambda function and will be using external libraries that are not included in the standard Lambda libraries. What action would minimize the Lambda compute time consumed?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: D</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03c37e-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03c37e-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Install the dependencies and external libraries at the beginning of the Lambda function.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create a Lambda deployment package that includes the external libraries.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Copy the external libraries to Amazon S3, and reference the external libraries to the S3 location.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Install the external libraries in Lambda to be available to all Lambda functions.<br></p>", "correct": true, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03c50e-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>During non-peak hours, a Developer wants to minimize the execution time of a full Amazon DynamoDB table scan without affecting normal workloads. The workloads average half of the strongly consistent read capacity units during non-peak hours. How would the Developer optimize this scan?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: B</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03c50e-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03c50e-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Use parallel scans while limiting the rate.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use sequential scans.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Increase read capacity units during the scan operation.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Change consistency to eventually consistent during the scan operation.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03c6a8-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A large e-commerce site is being designed to deliver static objects from Amazon S3. The Amazon S3 bucket will server more than 300 GET requests per second. What should be done to optimize performance? (Choose TWO)</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A,B</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03c6a8-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03c6a8-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Integrate Amazon CloudFront with Amazon S3.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Enable Amazon S3 cross-region replication.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Delete expired Amazon S3 server log files.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Configure Amazon S3 lifecycle rules.Randomize Amazon S3 key name prefixes.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Randomize Amazon S3 key name prefixes.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03c82e-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A legacy service has an XML-based SOAP interface. The Developer wants to expose the functionality of the service to external clients with the Amazon API Gateway. Which technique will accomplish this?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03c82e-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03c82e-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Create a RESTful API with the API Gateway; transform the incoming JSON into a valid XML message for the SOAP interface using mapping templates.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Create a RESTful API with the API Gateway; pass the incoming JSON to the SOAP interface through an Application Load Balancer.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create a RESTful API with the API Gateway; pass the incoming XML to the SOAP interface through an Application Load Balancer.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create a RESTful API with the API Gateway; transform the incoming XML into a valid message for the SOAP interface using mapping templates.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03c9b4-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer has an application that can upload tens of thousands of objects per second to Amazon S3 in parallel within a single AWS account. As part of new requirements, data stored in S3 must use server side encryption with AWS KMS (SSE-KMS). After creating this change, performance of the application is slower. Which of the following is MOST likely the cause of the application latency?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: B</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03c9b4-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03c9b4-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Amazon S3 throttles the rate at which uploaded objects can be encrypted using Customer Master Keys.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>The AWS KMS API calls limit is less than needed to achieve the desired performance.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>The client encryption of the objects is using a poor algorithm.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>KMS requires that an alias be used to create an independent display name that can be mapped to a CM.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03cb3a-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A customer wants to deploy its source code on an AWS Elastic Beanstalk environment. The customer needs to perform deployment with minimal outage and should only use existing instances to retain application access log. What deployment policy would satisfy these requirements?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03cb3a-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03cb3a-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Rolling.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>All at once.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Rolling with an additional batch.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Immutable.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03cca2-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer has setup an Amazon Kinesis Stream with 4 shards to ingest a maximum of 2500 records per second. A Lambda function has been configured to process these records. In which order will these records be processed?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03cca2-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03cca2-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Lambda will receive each record in the reverse order it was placed into the stream following a LIFO (last-in, first-out) method.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Lambda will receive each record in the exact order it was placed into the stream following a FIFO (first\u00ad-in, first-out) method.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Lambda will receive each record in the exact order it was placed into the stream following a FIFO (first\u00ad-in, first-out) method.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>The Developer can select FIFO, (first-in, first-out), LIFO (last-in, last-out), random, or request specific record using the getRecords AP.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03ce14-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>An organization must store thousands of sensitive audio and video files in an Amazon S3 bucket. Organizational security policies require that all data written to this bucket be encrypted. How can compliance with this policy be ensured?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: B</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03ce14-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03ce14-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Use AWS Lambda to send notifications to the security team if unencrypted objects are pun in the bucket.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Configure an Amazon S3 bucket policy to prevent the upload of objects that do not contain the x-amz\u00adserver-side-encryption header.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Create an Amazon CloudWatch event rule to verify that all objects stored in the Amazon S3 bucket are encrypted.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Configure an Amazon S3 bucket policy to prevent the upload of objects that contain the x-amz-server\u00adside-encryption header.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03cf86-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>An application is designed to use Amazon SQS to manage messages from many independent senders. Each sender's messages must be processed in the order they are received. Which SQS feature should be implemented by the Developer?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03cf86-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03cf86-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Configure each sender with a unique MessageGroupId.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Enable MessageDeduplicationIds on the SQS queue.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Configure each message with unique MessageGroupIds.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Enable ContentBasedDeduplication on the SQS queue.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03d0e4-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer created a dashboard for an application using Amazon API Gateway, Amazon S3, AWS Lambda, and Amazon RDS. The Developer needs an authentication mechanism allowing a user to sign in and view the dashboard. It must be accessible from mobile applications, desktops, and tablets, and must remember user preferences across platforms. Which AWS service should the Developer use to support this authentication scenario?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: B</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03d0e4-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03d0e4-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>AWS KMS.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Amazon Cognito.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>AWS Directory Service.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Amazon IAM.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03d238-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Lambda function is packaged for deployment to multiple environments, including development, test, production, etc. Each environment has unique set of resources such as databases, etc. How can the Lambda function use the resources for the current environment?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03d238-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03d238-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Apply tags to the Lambda functions.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Hardcore resources in the source code.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use environment variables for the Lambda functions.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Use separate function for development and production.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03d396-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer needs temporary access to resources in a second account. What is the MOST secure way to achieve this?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03d396-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03d396-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Use the Amazon Cognito user pools to get short-lived credentials for the second account.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create a dedicated IAM access key for the second account, and send it by mail.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create a cross-account access role, and use sts: AssumeRole API to get short-lived credentials.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Establish trust, and add an SSH key for the second account to the IAM user.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03d4f4-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer needs to use AWS X-Ray to monitor an application that is deployed on EC2 instances. What steps have to be executed to perform the monitoring?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03d4f4-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03d4f4-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Deploy the X-Ray SDK with the application and use X-Ray annotation.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Install the X-Ray daemon and instrument the application code.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Install the X-Ray daemon and configure it to forward data to Amazon CloudWatch Events.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Deploy the X-Ray SDK with the application and instrument the application code.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03d648-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer is creating an Auto Scaling group whose instances need to publish a custom metric to Amazon CloudWatch. Which method would be the MOST secure way to authenticate a CloudWatch PUT request?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: D</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03d648-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03d648-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Create an IAM user with PutMetricData permission and put the user credentials in a private repository; have applications pull the credentials as needed.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create an IAM user with PutMetricData permission, and modify the Auto Scaling launch configuration to inject the user credentials into the instance user data.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Modify the CloudWatch metric policies to allow the PutMetricData permission to instances from the Auto Scaling group.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create an IAM role with PutMetricData permission and modify the Auto Scaling launching configuration to launch instances using that role.<br></p>", "correct": true, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03d7b0-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer is working on an application that tracks hundreds of millions of product reviews in an Amazon DynamoDB table. The records include the data elements shown in the table. Which field, when used as the partition key, would result in the MOST consistent performance using DynamoDB? ![Question 87](images/question87.jpg)</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: B</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03d7b0-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03d7b0-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>starRating.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>reviewID.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>comment.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>productID.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03d90e-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A development team consists of 10 team members. Similar to a home directory for each team member, the manager wants to grant access to user-specific folders in an Amazon S3 bucket. For the team member with the username 'TeamMemberX', the snippet of the IAM policy looks like this. Instead of creating distinct policies for each team member, what approach can be used to make this policy snippet generic for all team members? ![Question 88](images/question88.jpg)</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03d90e-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03d90e-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Use IAM policy condition.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Use IAM policy principal.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use IAM policy variables.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use IAM policy resource.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03da58-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A company needs to encrypt data at rest, but it wants to leverage an AWS managed service using its own master key. Which of the following AWS service can be used to meet these requirements?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: B</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03da58-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03da58-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>SSE with Amazon S3.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>SSE with AWS KMS.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Client-side encryption.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>AWS IAM roles and policies.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03db98-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer has created a software package to be deployed on multiple EC2 instances using IAM roles. What actions could be performed to verify IAM access to get records from Amazon Kinesis Streams? (Select TWO)</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: D,E</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03db98-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03db98-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Use the AWS CLI to retrieve the IAM group.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Query Amazon EC2 metadata for in-line IAM policies.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Request a token from AWS STS, and perform a describe action.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Perform a get action using the ''-dry-run argument.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Validate the IAM role policy with the IAM policy simulator.<br></p>", "correct": true, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03dcec-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A company wants to implement a continuous integration for its workloads on AWS. The company wants to trigger unit test in its pipeline for commits-on its code repository, and wants to be notified of failure events in the pipeline. How can these requirements be met?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03dcec-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03dcec-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Store the source code in AWS CodeCommit. Create a CodePipeline to automate unit testing. Use Amazon SNS to trigger notifications of failure events.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Store the source code in GitHub. Create a CodePipeline to automate unit testing. Use Amazon SES to trigger notifications of failure events.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Store the source code on GitHub. Create a CodePipeline to automate unit testing. Use Amazon CloudWatch to trigger notifications of failure events.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Store the source code in AWS CodeCommit. Create a CodePipeline to automate unit testing. Use Amazon CloudWatch to trigger notification of failure events.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03de4a-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>An application takes 40 seconds to process instructions received in an Amazon SQS message. Assuming the SQS queue is configured with the default VisibilityTimeout value, what is the BEST way, upon receiving a message, to ensure that no other instances can retrieve a message that has already been processed or is currently being processed?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03de4a-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03de4a-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Use the ChangeMessageVisibility API to increase the VisibilityTimeout, then use the DeleteMessage API to delete the message.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Use the DeleteMessage API call to delete the message from the queue, then call DeleteQueue API to remove the queue.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use the ChangeMessageVisibility API to decrease the timeout value, then use the DeleteMessage API to delete the message.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use the DeleteMessageVisibility API to cancel the VisibilityTimeout, then use the DeleteMessage API to delete the message.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03dfa8-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer is developing an application that manages financial transactions. To improve security, multi-factor authentication (MFA) will be required as part of the login protocol. What services can the Developer use to meet these requirements?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: D</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03dfa8-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03dfa8-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Amazon DynamoDB to store MFA session data, and Amazon SNS to send MFA codes.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Amazon Cognito with MFA.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>AWS Directory Service.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>AWS IAM with MFA enabled.<br></p>", "correct": true, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03e0f2-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer is writing transactions into a DynamoDB table called 'SystemUpdates' that has 5 write capacity units. Which option has the highest read throughput?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: B</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03e0f2-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03e0f2-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Eventually consistent reads of 5 read capacity units reading items that are 4 KB in size.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Strongly consistent reads of 5 read capacity units reading items that are 4 KB in size.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Eventually consistent reads of 15 read capacity units reading items that are 1 KB in size.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Strongly consistent reads of 15 read capacity units reading items that are 1 KB in size.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03e246-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer has created an S3 bucket s3://mycoolapp and has enabled server across logging that points to the folder s3://mycoolapp/logs.The Developer moved 100 KB of Cascading Style Sheets (CSS) documents to the folder s3://mycoolapp/css, and then stopped work. When the developer came back a few days later, the bucket was 50 GB. What is the MOST likely cause of this situation?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: B</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03e246-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03e246-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>The CSS files were not compressed and S3 versioning was enabled.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>S3 replication was enabled on the bucket.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Logging into the same bucket caused exponential log growth.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>An S3 lifecycle policy has moved the entire CSS file to S3 Infrequent Access.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03e39a-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer is testing a Docker-based application that uses the AWS SDK to interact with Amazon DynamoDB. In the local development environment, the application has used IAM access keys. The application is now ready for deployment onto an ECS cluster. How should the application authenticate with AWS services in production?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03e39a-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03e39a-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Configure an ECS task IAM role for the application to use.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Refactor the application to call AWS STS AssumeRole based on an instance role.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Configure AWS access key/secret access key environment variables with new credentials.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Configure the credentials file with a new access key/secret access key.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03e4ee-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A company is using AWS CodeBuild to compile a website from source code stored in AWS CodeCommit. A recent change to the source code has resulted in the CodeBuild project being unable to successfully compile the website. How should the Developer identify the cause of the failures?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03e4ee-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03e4ee-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Modify the buildspec.yml file to include steps to send the output of build commands to Amazon CloudWatch.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use a custom Docker image that includes the AWS X-Ray agent in the AWS CodeBuild project configuration.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Check the build logs of the failed phase in the last build attempt in the AWS CodeBuild project build history.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Manually re-run the build process on a local machine so that the output can be visualized.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03e64c-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>For a deployment using AWS CodeDeploy, what is the run order of the hooks for in-place deployments?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: B</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03e64c-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03e64c-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Before Install -> Application Stop -> Application Start -> After Install.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Application Stop -> Before Install -> After Install -> Application Start.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Before Install -> Application Stop -> Validate Service -> Application Start.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Application Stop -> Before Install -> Validate Service -> Application Start.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03e796-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer executed a AWS CLI command and received the error shown below. What action should the Developer perform to make this error human-readable? ![Question 99](images/question99.jpg)</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: B</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03e796-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03e796-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Make a call to AWS KMS to decode the message.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use the AWS STS decode-authorization-message API to decode the message.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Use an open source decoding library to decode the message.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use the AWS IAM decode-authorization-message API to decode this message.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03e8ea-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer uses AWS CodeDeploy to automate application deployment that connects to an external MySQL database. The Developer wants to securely access the encrypted secrets, such as API keys and database passwords. Which of the following solutions would involve the LEAST administrative effort?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03e8ea-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03e8ea-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Save the secrets in Amazon S3 with AWS KMS server-side encryption, and use a signed URL to access them by using the IAM role from Amazon EC2 instances.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Use the instance metadata to store the secrets and to programmatically access the secrets from EC2 instances.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use the Amazon DynamoDB client-side encryption library to save the secrets in DynamoDB and to programmatically access the secrets from EC2 instances.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use AWS SSM Parameter Store to store the secrets and to programmatically access them by using the IAM role from EC2 instances.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03ea5c-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>An application stops working with the following error: The specified bucket does not exist. Where is the BEST place to start the root cause analysis?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: D</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03ea5c-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03ea5c-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Check the Elastic Load Balancer logs for DeleteBucket requests.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Check the application logs in Amazon CloudWatch Logs for Amazon S3 DeleteBucket errors.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Check AWS X-Ray for Amazon S3 DeleteBucket alarms.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Check AWS CloudTrail for a DeleteBucket event.<br></p>", "correct": true, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03eba6-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer will be using the AWS CLI on a local development server to manage AWS services. What can be done to ensure that the CLI uses the Developer's IAM permissions when making commands?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: B</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03eba6-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03eba6-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Specify the Developer's IAM access key ID and secret access key as parameters for each CLI command.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Run the aws configure CLI command, and provide the Developer's IAM access key ID and secret access key.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Specify the Developer's IAM user name and password as parameters for each CLI command.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use the Developer's IAM role when making the CLI command.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03ecfa-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>An application stores images in an S3 bucket. Amazon S3 event notifications are used to trigger a Lambda function that resizes the images. Processing each image takes less than a second. How will AWS Lambda handle the additional traffic?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03ecfa-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03ecfa-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Lambda will scale out to execute the requests concurrently.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Lambda will handle the requests sequentially in the order received.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Lambda will process multiple images in a single execution.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Lambda will add more compute to each execution to reduce processing time.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03ef48-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A company is building a stock trading application that requires sub-millisecond latency in processing trading requests. Amazon DynamoDB is used to store all the trading data that is used to process each request. After load testing the application, the development team found that due to data retrieval times, the latency requirement is not satisfied. Because of sudden high spikes in the number of requests, DynamoDB read capacity has to be significantly over-provisioned to avoid throttling. What steps should be taken to meet latency requirements and reduce the cost of running the application?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03ef48-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03ef48-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Add Global Secondary Indexes for trading data.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Store trading data in Amazon S3 and use Transfer Acceleration.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Add retries with exponential back-off for DynamoDB queries.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use DynamoDB Accelerator to cache trading data.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03f0c4-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer created a Lambda function for a web application backend. When testing the Lambda function from the AWS Lambda console, the Developer can see that the function is being executed, but there is no log data being generated in Amazon CloudWatch Logs, even after several minutes. What could cause this situation?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03f0c4-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03f0c4-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>The Lambda function does not have any explicit log statements for the log data to send it to CloudWatch Logs.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>The Lambda function is missing CloudWatch Logs as a source trigger to send log data.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>The execution role for the Lambda function is missing permissions to write log data to the CloudWatch Logs.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>The Lambda function is missing a target CloudWatch Log group.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03f222-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer wants to use AWS X-Ray to trace a user request end-to-end throughput the software stack. The Developer made the necessary changes in the application tested it, and found that the application is able to send the traces to AWS X-Ray. However, when the application is deployed to an EC2 instance, the traces are not availableWhich of the following could create this situation? (Choose TWO)</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: B,E</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03f222-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03f222-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>The traces are reaching X-Ray, but the Developer does not have access to view the records.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>The X-Ray daemon is not installed on the EC2 instance.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>The X-Ray endpoint specified in the application configuration is incorrect.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>The instance role does not have 'xray:BatchGetTraces' and 'xray:GetTraceGraph' permissions.The instance role does not have 'xray:PutTraceSegments' and 'xray:PutTelemetryRecords' permissions.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>The instance role does not have 'xray:PutTraceSegments' and 'xray:PutTelemetryRecords' permissions.<br></p>", "correct": true, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03f394-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>An application has hundreds of users. Each user may use multiple devices to access the application. The Developer wants to assign unique identifiers to these users regardless of the device they use. Which of the following methods should be used to obtain unique identifiers?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: D</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03f394-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03f394-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Create a user table in Amazon DynamoDB as key-value pairs of users and their devices. Use these keys as unique identifiers.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use IAM-generated access key IDs for the users as the unique identifier, but do not store secret keys.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Implement developer-authenticated identities by using Amazon Cognito, and get credentials for these identities.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Assign IAM users and roles to the users. Use the unique IAM resource ID as the unique identifier.<br></p>", "correct": true, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03f4fc-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>What are the steps to using the AWS CLI to launch a templatized serverless application?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03f4fc-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03f4fc-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Use AWS CloudFormation get-template then CloudFormation execute-change-set.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use AWS CloudFormation validate-template then CloudFormation create-change-set.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use AWS CloudFormation package then CloudFormation deploy.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Use AWS CloudFormation create-stack then CloudFormation update-stack.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03f650-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A deployment package uses the AWS CLI to copy files into any S3 bucket in the account, using access keys stored in environment variables. The package is running on EC2 instances, and the instances have been modified to run with an assumed IAM role and a more restrictive policy that allows access to only one bucket. After the change, the Developer logs into the host and still has the ability to write into all of the S3 buckets in that account. What is the MOST likely cause of this situation?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: B</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03f650-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03f650-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>An IAM inline policy is being used on the IAM role.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>An IAM managed policy is being used on the IAM role.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>The AWS CLI is corrupt and needs to be reinstalled.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>The AWS credential provider looks for instance profile credentials last.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03f7b8-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>An application overwrites an object in Amazon S3, and then immediately reads the same object. Why would the application sometimes retrieve the old version of the object?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03f7b8-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03f7b8-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>S3 overwrite PUTS are eventually consistent, so the application may read the old object.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>The application needs to add extra metadata to label the latest version when uploading to Amazon S3.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>All S3 PUTS are eventually consistent, so the application may read the old object.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>The application needs to explicitly specify latest version when retrieving the object.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03f90c-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>An application under development is required to store hundreds of video files. The data must be encrypted within the application prior to storage, with a unique key for each video file. How should the Developer code the application?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03f90c-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03f90c-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Use the KMS Encrypt API to encrypt the data. Store the encrypted data key and data.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use a cryptography library to generate an encryption key for the application. Use the encryption key to encrypt the data. Store the encrypted data.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use the KMS GenerateDataKey API to get a data key. Encrypt the data with the data key. Store the encrypted data key and data.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Upload the data to an S3 bucket using server side-encryption with an AWS KMS key.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03fa7e-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A developer is testing an application that invokes an AWS Lambda function asynchronously. During the testing phase, the Lambda function fails to process after two retries. How can the developer troubleshoot the failure?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: B</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03fa7e-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03fa7e-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Configure AWS CloudTrail logging to investigate the invocation failures.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Configure Dead Letter Queues by sending events to Amazon SQS for investigatio.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Configure Amazon Simple Workflow Service to process any direct unprocessed events.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Configure AWS Config to process any direct unprocessed events.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03fbbe-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A developer is setting up Amazon API Gateway for their company's products. The API will be used by registered developers to query and update their environments. The company wants to limit the amount of requests end users can send for both cost and security reasons. Management wants to offer registered developers the option of buying larger packages that allow for more requests. How can the developer accomplish this with the LEAST amount of overhead management?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: D</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03fbbe-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03fbbe-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Enable throttling for the API Gateway stage. Set a value for both the rate and burst capacity. If a registered user chooses a larger package, create a stage for them, adjust the values, and share the new URL with them.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Set up Amazon CloudWatch API logging in API Gateway. Create a filter based on the user and requestTime fields and create an alarm on this filter. Write an AWS Lambda function to analyze the values and requester information, and respond accordingly. Set up the function as the target for the alarm. If a registered user chooses a larger package, update the Lambda code with the values.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Enable Amazon CloudWatch metrics for the API Gateway stage. Set up CloudWatch alarms based off the Count metric and the ApiName, Method, Resource, and Stage dimensions to alerts when request rates pass the threshold. Set the alarm action to Deny. If a registered user chooses a larger package, create a user-specific alarm and adjust the values.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Set up a default usage plan, specify values for the rate and burst capacity, and associate it with a stage. If a registered user chooses a larger package, create a custom plan with the appropriate values and associate the plan with the user.<br></p>", "correct": true, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03fd3a-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A developer is refactoring a monolithic application. The application takes a POST request and performs several operations. Some of the operations are in parallel while others run sequentially. These operations have been refactored into individual AWS Lambda functions. The POST request will be processed by Amazon API Gateway. How should the developer invoke the Lambda functions in the same sequence using API Gateway?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: D</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03fd3a-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03fd3a-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Use Amazon SQS to invoke the Lambda functions.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use an AWS Step Functions activity to run the Lambda functions.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use Amazon SNS to trigger the Lambda functions.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use an AWS Step Functions state machine to orchestrate the Lambda functions.<br></p>", "correct": true, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03fe7a-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A company is adding stored value (or gift card) capability to its highly popular casual gaming website. Users need to be able to trade this value for other users' items on the platform. This would require both users' records be updated as a single transaction, or both users' records to be completely rolled back. Which AWS database options can provide the transactional capability required for this new feature? (Choose TWO)</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: B,D</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03fe7a-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03fe7a-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Amazon DynamoDB with operations made with the ConsistentRead parameter set to true.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Amazon ElastiCache for Memcached with operations made within a transaction block.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Amazon Aurora MySQL with operations made within a transaction block.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Amazon DynamoDB with reads and writes made using Transact* operations.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Amazon Redshift with operations made within a transaction block.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec03ffce-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A developer is creating an AWS Lambda function that generates a new file each time it runs. Each new file must be checked into an AWS CodeCommit repository hosted in the same AWS account. How should the developer accomplish this?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec03ffce-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec03ffce-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>When the Lambda function starts, use the Git CLI to clone the repository. Check the new file into the cloned repository and push the change.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>After the new file is created in Lambda, use cURL to invoke the CodeCommit API. Send the file to the repository.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use an AWS SDK to instantiate a CodeCommit client. Invoke the put_file method to add the file to the repository.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Upload the new to an Amazon S3 bucket. Create an AWS Step Function to accept S3 events. In the Step Function, add the new file to the repository.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec040118-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A developer must ensure that the IAM credentials used by an application in Amazon EC2 are not misused or compromised. What should the developer use to keep user credentials secure?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: D</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec040118-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec040118-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Environment variables.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>AWS credentials file.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Instance profile credentials.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Command line options.<br></p>", "correct": true, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec040258-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A company has an application where reading objects from Amazon S3 is based on the type of user. The user types are registered user and guest user. The company has 25,000 users and is growing. Information is pulled from an S3 bucket depending on the user type. Which approaches are recommended to provide access to both user types? (Choose TWO)</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A,B</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec040258-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec040258-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Provide a different access key and secret access key in the application code for registered users and guest users to provide read access to the objects.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Use S3 bucket policies to restrict read access to specific IAM users.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Use Amazon Cognito to provide access using authenticated and unauthenticated roles.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create a new IAM user for each user and grant read access.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use the AWS IAM service and let the application assume the different roles using the AWS Security Token Service (AWS STS) AssumeRole action depending on the type of user and provide read access to Amazon S3 using the assumed role.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec0403b6-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A company has 25,000 employees and is growing. The company is creating an application that will be accessible to its employees only. A developer is using Amazon S3 to store images and Amazon RDS to store application data. The company requires that all employee information remain in the legacy Security Assertion Markup Language (SAML) employee directory only and is not interested in mirroring any employee information on AWS. How can the developer provide authorized access for the employees who will be using this application so each employee can access their own application data only?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec0403b6-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec0403b6-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Use Amazon VPC and keep all resources inside the VPC, and use a VPC link for the S3 bucket with the bucket policy.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use Amazon Cognito user pools, federate with the SAML provider, and use user pool groups with an IAM policy.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use an Amazon Cognito identity pool, federate with the SAML provider, and use an IAM condition key with a value for the cognito-identity.amazonaws.com:sub variable to grant access to the employees.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Create a unique IAM role for each employee and have each employee assume the role to access the application so they can access their personal data only.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec040514-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A company has developed a new serverless application using AWS Lambda functions that will be deployed using the AWS Serverless Application Model (AWS SAM) CLI. Which step should the developer complete prior to deploying the application?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec040514-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec040514-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Compress the application to a .zip file and upload it into AWS Lambda.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Test the new AWS Lambda function by first tracing it in AWS X-Ray.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Bundle the serverless application using a SAM package.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create the application environment using the eb create my-env command.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec040654-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>An application needs to encrypt data that is written to Amazon S3 where the keys are managed in an on-premises data center, and the encryption is handled by S3. Which type of encryption should be used?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec040654-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec040654-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Use server-side encryption with Amazon S3-managed keys.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use server-side encryption with AWS KMS-managed keys.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use client-side encryption with customer master keys.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Use server-side encryption with customer-provided keys.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec0407a8-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A development team is working on a mobile app that allows users to upload pictures to Amazon S3. The team expects the app will be used by hundreds of thousands of users during a single event simultaneously. Once the pictures are uploaded, the backend service will scan and parse the pictures for inappropriate content. Which approach is the MOST resilient way to achieve this goal, which also smooths out temporary volume spikes for the backend service?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: B</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec0407a8-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec0407a8-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Develop an AWS Lambda function to check the upload folder in the S3 bucket. If new uploaded pictures are detected, the Lambda function will scan and parse them.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Once a picture is uploaded to Amazon S3, publish the event to an Amazon SQS queue. Use the queue as an event source to trigger an AWS Lambda function. In the Lambda function, scan and parse the picture.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>When the user uploads a picture, invoke an API hosted in Amazon API Gateway. The API will invoke an AWS Lambda function to scan and parse the picture.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create a state machine in AWS Step Functions to check the upload folder in the S3 bucket. If a new picture is detected, invoke an AWS Lambda function to scan and parse it.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec040910-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A development team wants to run their container workloads on Amazon ECS. Each application container needs to share data with another container to collect logs and metrics. What should the developer team do to meet these requirements?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec040910-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec040910-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Create two pod specifications. Make one to include the application container and the other to include the other container. Link the two pods together.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Create two task definitions. Make one to include the application container and the other to include the other container. Mount a shared volume between the two tasks.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create one task definition. Specify both containers in the definition. Mount a shared volume between those two containers.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create a single pod specification. Include both containers in the specification. Mount a persistent volume to both containers.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec040a64-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>An ecommerce startup is preparing for an annual sales event. As the traffic to the company's application increases, the development team wants to be notified when the Amazon EC2 instance's CPU utilization exceeds 80%. Which solution will meet this requirement?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec040a64-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec040a64-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Create a custom Amazon CloudWatch alarm that sends a notification to an Amazon SNS topic when the CPU utilization exceeds 80%.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Create a custom AWS Cloud Trail alarm that sends a notification to an Amazon SNS topic when the CPU utilization exceeds 80%.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create a cron job on the EC2 instance that executes the \u2013describe-instance-information command on the host instance every 15 minutes and sends the results to an Amazon SNS topic.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create an AWS Lambda function that queries the AWS CloudTrail logs for the CPUUtilization metric every 15 minutes and sends a notification to an Amazon SNS topic when the CPU utilization exceeds 80%.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec040bc2-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>An application running on Amazon EC2 opens connections to an Amazon RDS SQL Server database. The developer does not want to store the user name and password for the database in the code. The developer would also like to automatically rotate the credentials. What is the MOST secure way to store and access the database credentials?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: B</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec040bc2-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec040bc2-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Create an IAM role that has permissions to access the database. Attach the role to the EC2 instance.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use AWS Secrets Manager to store the credentials. Retrieve the credentials from Secrets Manager as needed.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Store the credentials in an encrypted text file in an Amazon S3 bucket. Configure the EC2 instance's user data to download the credentials from Amazon S3 as the instance boots.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Store the user name and password credentials directly in the source code. No further action is needed because the source code is stored in a private repository.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec040d16-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A developer is updating an application deployed on AWS Elastic Beanstalk. The new version is incompatible with the old version. To successfully deploy the update, a full cutover to the new, updated version must be performed on all instances at one time, with the ability to roll back changes in case of a deployment failure in the new version. How can this be performed with the LEAST amount of downtime?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: D</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec040d16-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec040d16-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Use the Elastic Beanstalk All at once deployment policy to update all instances simultaneously.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Perform an Elastic Beanstalk Rolling with additional batch deployment.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Deploy the new version in a new Elastic Beanstalk environment and swap environment URLs.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Perform an Elastic Beanstalk Rolling deployment.<br></p>", "correct": true, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec040e60-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A developer is writing a web application that must share secure documents with end users. The documents are stored in a private Amazon S3 bucket. The application must allow only authenticated users to download specific documents when requested, and only for a duration of 15 minutes. How can the developer meet these requirements?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: B</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec040e60-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec040e60-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Copy the documents to a separate S3 bucket that has a lifecycle policy for deletion after 15 minutes.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create a presigned S3 URL using the AWS SDK with an expiration time of 15 minutes.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Create a presigned S3 URL using the AWS SDK with an expiration time of 15 minutes.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create a presigned S3 URL using the AWS SDK with an expiration time of 15 minutes.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec040fa0-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A company is developing a report executed by AWS Step Functions, Amazon CloudWatch shows errors in the Step Functions task state machine. To troubleshoot each task, the state input needs to be included along with the error message in the state output. Which coding practice can preserve both the original input and the error for the state?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec040fa0-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec040fa0-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Use ResultPath in a Catch statement to include the error with the original input.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Use InputPath in a Catch statement and set the value to null.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use Error Equals in a Retry statement to include the error with the original input.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use OutputPath in a Retry statement and set the value to $.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec0410e0-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A developer receives the following error message when trying to launch or terminate an Amazon EC2 instance using a boto3 script. What should the developer do to correct this error message? [Question 129](images/question129.jpg)</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: B</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec0410e0-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec0410e0-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Assign an IAM role to the EC2 instance to allow necessary API calls on behalf of the client.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Implement an exponential backoff algorithm for optimizing the number of API requests made to Amazon EC2.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Increase the overall network bandwidth to handle higher API request rates.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Upgrade to the latest AWS CLI version so that boto3 can handle higher request rates.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    {"question_id": "#ec0412ca-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>Given the following AWS CloudFormation template. What is the MOST efficient way to reference the new Amazon S3 bucket from another AWS CloudFormation template? [Question 130](images/question130.jpg)</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec0412ca-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec0412ca-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Add an Export declaration to the Outputs section of the original template and use ImportValue in other templates.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Add Exported: true to the Contentbucket in the original template and use ImportResource in other templates.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create a custom AWS CloudFormation resource that gets the bucket name from the ContentBucket resource of the first stack.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Use Fn::Include to include the existing template in other templates and use the ContentBucket resource directly.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
    ]
  }