var DVA_C02_Part6 = 
{
    "msg": "Quiz Questions",
    "data": [
      {"question_id": "#ec051f76-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer is designing a new application that uses Amazon S3. To satisfy compliance requirements, the Developer must encrypt the data at rest. How can the Developer accomplish this?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: D</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec051f76-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec051f76-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Use s3:x-amz-acl as a condition in the S3 bucket policy.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use Amazon RDS with default encryption.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use aws:SecureTransport as a condition in the S3 bucket policy.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Turn on S3 default encryption for the S3 bucket.<br></p>", "correct": true, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec052214-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer wants to find a list of items in a global secondary index from an Amazon DynamoDB table. Which DynamoDB API call can the Developer use in order to consume the LEAST number of read capacity units?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec052214-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec052214-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Scan operation using eventually-consistent reads.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Query operation using strongly-consistent reads.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Query operation using eventually-consistent reads.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Scan operation using strongly-consistent reads.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec05234a-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer has published an update to an application that is served to a global user base using Amazon CloudFront. After deploying the application, users are not able to see the updated changes. How can the Developer resolve this issue?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec05234a-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec05234a-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Remove the origin from the CloudFront configuration and add it again.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Disable forwarding of query strings and request headers from the CloudFront distribution configuration.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Invalidate all the application objects from the edge caches.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Disable the CloudFront distribution and enable it again to update all the edge locations.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec05248a-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer must deploy a new AWS Lambda function using an AWS CloudFormation template. Which procedures will deploy a Lambda function? (Select TWO)</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: B,D</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec05248a-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec05248a-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Upload the code to an AWS CodeCommit repository, then add a reference to it in an AWS::Lambda::Function resource in the template.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create an AWS::Lambda::Function resource in the template, then write the code directly inside the CloudFormation template.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Upload a .ZIP file containing the function code to Amazon S3, then add a reference to it in an AWS::Lambda::Function resource in the template.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Upload a .ZIP file to AWS CloudFormation containing the function code, then add a reference to it in an AWS::Lambda::Function resource in the template.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Upload the function code to a private Git repository, then add a reference to it in an AWS::Lambda::Function resource in the template.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec0525fc-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>How should custom libraries be utilized in AWS Lambda?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: D</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec0525fc-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec0525fc-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Host the library on Amazon S3 and reference to it from the Lambda function.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Install the library locally and upload a ZIP file of the Lambda function.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Import the necessary Lambda blueprint when creating the function.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Modify the function runtime to include the necessary library.<br></p>", "correct": true, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec05275a-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A company needs to secure its existing website running behind an Elastic Load Balancer. The website's Amazon EC2 instances are CPU-constrained. What should be done to secure the website while not increasing the CPU load on the EC2 web servers? (Select TWO)</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: B,D</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec05275a-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec05275a-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Configure an Elastic Load Balancer with SSL pass-through.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Configure SSL certificates on an Elastic Load Balancer.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Configure an Elastic Load Balancer with a Loadable Storage System.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Install SSL certificates on the EC2 instances.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Configure an Elastic Load Balancer with SSL termination.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec0528a4-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer is writing an imaging micro service on AWS Lambda. The service is dependent on several libraries that are not available in the Lambda runtime environment. Which strategy should the Developer follow to create the Lambda deployment package?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: B</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec0528a4-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec0528a4-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Create a ZIP file with the source code and all dependent libraries.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create a ZIP file with the source code and a script that installs the dependent libraries at runtime.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Create a ZIP file with the source code. Stage the dependent libraries on an Amazon S3 bucket indicated by the Lambda environment variable LD_LIBRARY_PATH.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create a ZIP file with the source code and a buildspec.yaml file that installs the dependent libraries on AWS Lambda.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec0529ee-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer is designing a fault-tolerant environment where client sessions will be saved. How can the Developer ensure that no sessions are lost if an Amazon EC2 instance fails?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec0529ee-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec0529ee-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Use sticky sessions with an Elastic Load Balancer target group.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Use Amazon SQS to save session data.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use Amazon DynamoDB to perform scalable session handling.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use Elastic Load Balancer connection draining to stop sending requests to failing instances.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec052b38-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>In a move toward using microservices, a company's Management team has asked all Development teams to build their services so that API requests depend only on that service's data store. One team is building a Payments service which has its own database; the service needs data that originates in the Accounts database. Both are using Amazon DynamoDB. What approach will result in the simplest, decoupled, and reliable method to get near-real time updates from the Accounts database?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: D</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec052b38-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec052b38-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Use Amazon Glue to perform frequent ETL updates from the Accounts database to the Payments database.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use Amazon ElastiCache in Payments, with the cache updated by triggers in the Accounts database.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use Amazon Kinesis Data Firehouse to deliver all changes from the Accounts database to the Payments database.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use Amazon DynamoDB Streams to deliver all changes from the Accounts database to the Payments database.<br></p>", "correct": true, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec052c8c-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A company needs a fully-managed source control service that will work in AWS. The service must ensure that revision control synchronizes multiple distributed repositories by exchanging sets of changes peer-to-peer. All users need to work productively even when not connected to a network. Which source control service should be used?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec052c8c-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec052c8c-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Subversion.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>AWS CodeBuild.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>AWS CodeCommit.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>AWS CodeStar.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec052dc2-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer is writing a serverless application that requires that an AWS Lambda function be invoked every 10 minutes. What is an automated and serverless way to trigger the function?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec052dc2-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec052dc2-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Deploy an Amazon EC2 instance based on Linux, and edit its /etc/crontab file by adding a command to periodically invoke the Lambda function.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Configure an environment variable named PERIOD for the Lambda function. Set the value to 600.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create an Amazon CloudWatch Events rule that triggers on a regular schedule to invoke the Lambda function.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Create an Amazon SNS topic that has a subscription to the Lambda function with a 600-second timer.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec052f0c-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A company is building an application to track athlete performance using an Amazon DynamoDB table. Each item in the table is identified by a partition key (user_id) and a sort key (sport_name). The table design is shown below. (Note: Not all table attributes are shown) A Developer is asked to write a leaderboard application to display the top performers (user_id) based on the score for each sport_name. What process will allow the Developer to extract results MOST efficiently from the DynamoDB table? [Question 337](images/question337.jpg)</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: B</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec052f0c-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec052f0c-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Use a DynamoDB query operation with the key attributes of user_id and sport_name and order the results based on the score attribute.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create a global secondary index with a partition key of sport_name and a sort key of score, and get the results.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Use a DynamoDB scan operation to retrieve scores and user_id based on sport_name, and order the results based on the score attribute.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create a local secondary index with a primary key of sport_name and a sort key of score and get the results based on the score attribute.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec053056-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer is creating a mobile application that will not require users to log in. What is the MOST efficient method to grant users access to AWS resources?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec053056-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec053056-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Use an identity provider to securely authenticate with the application.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create an AWS Lambda function to create an IAM user when a user accesses the application.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create credentials using AWS KMS and apply these credentials to users when using the application.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Use Amazon Cognito to associate unauthenticated users with an IAM role that has limited access to resources.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec0531a0-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>An application running on Amazon EC2 instances must access objects within an Amaon S3 busket that are encrypted using server-side encryption using AWS KMS encryption keys (SSE-KMS). The application must have access to the customer master key (CMK) to decrypt the objects. Which combination of steps will grant the application access? (Select TWO)</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A,E</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec0531a0-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec0531a0-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Write an S3 bucket policy that grants the bucket access to the key.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Grant access to the key in the IAM EC2 role attached to the application's EC2 instances.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Write a key policy that enables IAM policies to grant access to the key.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Grant access to the key in the S3 bucket's ACL.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create a Systems Manager parameter that exposes the KMS key to the EC2 instances.<br></p>", "correct": true, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec0532f4-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>What does an Amazon SQS delay queue accomplish?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec0532f4-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec0532f4-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Messages are hidden for a configurable amount of time when they are first added to the queue.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Messages are hidden for a configurable amount of time after they are consumed from the queue.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>The consumer can poll the queue for a configurable amount of time before retrieving a message.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Message cannot be deleted for a configurable amount of time after they are consumed from the queue.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec053434-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A company has multiple Developers located across the globe who are updating code incrementally for a development project. When Developers upload code concurrently, internet connectivity is slow and it is taking a long time to upload code for deployment in AWS Elastic Beanstalk. Which step will result in minimized upload and deployment time with the LEAST amount of administrative effort?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec053434-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec053434-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Allow the Developers to upload the code to an Amazon S3 bucket, and deploy it directly to Elastic Beanstalk.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Allow the Developers to upload the code to a central FTP server to deploy the application to Elastic Beanstalk.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create an AWS CodeCommit repository, allow the Developers to commit code to it, and then directly deploy the code to Elastic Beanstalk.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Create a code repository on an Amazon EC2 instance so that all Developers can update the code, and deploy the application from the instance to Elastic Beanstalk.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec05357e-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A company recently migrated its web, application and NoSQL database tiers to AWS. The company is using Auto Scaling to scale the web and application tiers. More than 95 percent of the Amazon DynamoDB requests are repeated read requests. How can the DynamoDB NoSQL tier be scaled up to cache these repeated requests?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: B</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec05357e-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec05357e-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Amazon EMR.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Amazon DynamoDB Accelerator.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Amazon SQS.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Amazon CloudFront.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec0536be-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Development team is working on a case management solution that allows medical claims to be processed and reviewed. Users log in to provide information related to their medical and financial situations. As part of the application, sensitive documents such as medical records, medical imaging, bank statements, and receipts are uploaded to Amazon S3. All documents must be securely transmitted and stored. All access to the documents must be recorded for auditing. What is the MOST secure approach?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: D</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec0536be-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec0536be-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Use S3 default encryption using Advanced Encryption Standard-256 (AES-256) on the destination bucket.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use Amazon Cognito for authorization and authentication to ensure the security of the application and documents.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use AWS Lambda to encrypt and decrypt objects as they are placed into the S3 bucket.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use client-side encryption/decryption with Amazon S3 and AWS KMS.<br></p>", "correct": true, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec053812-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A company has an internet-facing application that uses Web Identity Federation to obtain a temporary credential from AWS Security Token Service (AWS STS). The app then uses the token to access AWS services. Review the following response: Based on the response displayed what permissions are associated with the call from the application? [Question 344](images/question344.jpg)</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec053812-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec053812-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Permissions associated with the role AROACLKWSDQRAOEXAMPLE:app1.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Permissions associated with the default role used when the AWS service was built.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Permission associated with the IAM principal that owns the AccessKeyID ASgeIAIOSFODNN7EXAMPLE.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Permissions associated with the account that owns the AWS service.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec053970-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer is using AWS CLI, but when running list commands on a large number of resources, it is timing out. What can be done to avoid this time-out?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec053970-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec053970-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Use pagination.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Use shorthand syntax.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use parameter values.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use quoting strings.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec053ab0-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>Where can PortMapping be defined when launching containers in Amazon ECS?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: D</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec053ab0-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec053ab0-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Security groups.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Amazon Elastic Container Registry (Amzon ECR).<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Container agent.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Task definition.<br></p>", "correct": true, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec053bf0-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>An organization is storing large files in Amazon S3, and is writing a web application to display meta-data about the files to end-users. Based on the metadata a user selects an object to download. The organization needs a mechanism to index the files and provide single-digit millisecond latency retrieval for the metadata. What AWS service should be used to accomplish this?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec053bf0-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec053bf0-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Amazon DynamoDB.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Amazon EC2.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>AWS Lambda.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Amazon RDS.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec053d30-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>While developing an application that runs on Amazon EC2 in an Amazon VPC, a Developer identifies the need for centralized storage of application-level logs. Which AWS service can be used to securely store these logs?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: B</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec053d30-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec053d30-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Amazon EC2 VPC Flow Logs.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Amazon CloudWatch Logs.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Amazon CloudSearch.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>AWS CloudTrail<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec053f56-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A stock market monitoring application uses Amazon Kinesis for data ingestion. During simulated tests of peak data rates, the Kinesis stream cannot keep up with the incoming data. What step will allow Kinesis to accommodate the traffic during peak hours?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec053f56-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec053f56-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Install the Kinesis Producer Library (KPL) for ingesting data into the stream.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Reduce the data retention period to allow for more data ingestion using. DecreaseStreamRetentionPeriod.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Increase the shard count of the stream using UpdateShardCount.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Ingest multiple records into the stream in a single call using PutRecords.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec0540aa-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A company has an AWS CloudFormation template that is stored as a single file. The template is able to launch and create a full infrastructure stack. Which best practice would increase the maintainability of the template?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec0540aa-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec0540aa-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Use nested stacks for common template patterns.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Embed credentials to prevent typos.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Remove mappings to decrease the number of variables.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use AWS::Include to reference publicly-hosted template files.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec0541f4-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>An on-premises application makes repeated calls to store files to Amazon S3. As usage of the application has increased, 'LimitExceeded' errors are being logged. What should be changed to fix this error?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec0541f4-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec0541f4-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Implement exponential backoffs in the application.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Load balance the application to multiple servers.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Move the application to Amazon EC2.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Add a one second delay to each API call.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec05433e-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A company caches session information for a web application in an Amazon DynamoDB table. The company wants an automated way to delete old items from the table. What is the simplest way to do this?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: B</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec05433e-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec05433e-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Write a script that deletes old records; schedule the scripts as a cron job on an Amazon EC2 instance.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Add an attribute with the expiration time; enable the Time To Live feature based on that attribute.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Each day, create a new table to hold session data; delete the previous day's table.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Add an attribute with the expiration time; name the attribute ItemExpiration.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec054488-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>An application is expected to process many files. Each file takes four minutes to process each AWS Lambda invocation. The Lambda function does not return any important data. What is the fastest way to process all the files?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec054488-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec054488-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>First split the files to make them smaller, then process with synchronous RequestResponse Lambda invocations.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Make synchronous RequestResponse Lambda invocations and process the files one by one.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Make asynchronous Event Lambda invocations and process the files in parallel.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>First join all the files, then process it all at once with an asynchronous Event Lambda invocation.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec0545d2-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>The upload of a 15 GB object to Amazon S3 fails. The error message reads: 'Your proposed upload exceeds the maximum allowed object size.' What technique will allow the Developer to upload this object?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec0545d2-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec0545d2-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Upload the object using the multi-part upload API.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Upload the object over an AWS Direct Connect connection.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Contact AWS Support to increase the object size limit.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Upload the object to another AWS region.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec054712-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>AWS CodeBuild builds code for an application, creates the Docker image, pushes the image to Amazon Elastic Container Registry (Amazon ECR), and tags the image with a unique identifier. If the Developers already have AWS CLI configured on their workstations, how can the Docker images be pulled to the workstations?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: B</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec054712-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec054712-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Run the following:docker pull REPOSITORY URI : TAG.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Run the output of the following:aws ecr get-login and then run: docker pull REPOSITORY URI : TAG.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Run the following:aws ecr get-login and then run: docker pull REPOSITORY URI : TAG.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Run the output of the following: aws ecr get-download-url-for-layer and then run: docker pull REPOSITORY URI : TAG.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec054866-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A web application is designed to allow new users to create accounts using their email addresses. The application will store attributes for each user, and is expecting millions of user to sign up. What should the Developer implement to achieve the design goals?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec054866-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec054866-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Amazon Cognito user pools.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>AWS Mobile Hub user data storage.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Amazon Cognito Sync.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>AWS Mobile Hub cloud logic.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec05499c-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A company needs a new REST API that can return information about the contents of an Amazon S3 bucket, such as a count of the objects stored in it. The company has decided that the new API should be written as a microservice using AWS Lambda and Amazon API Gateway. How should the Developer ensure that the microservice has the necessary access to the Amazon S3 bucket, while adhering to security best practices?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec05499c-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec05499c-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Create an IAM user that has permissions to access the Amazon S3 bucket, and store the IAM user credentials in the Lambda function source code.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create an IAM role that has permissions to access the Amazon S3 bucket and assign it to the Lambda function as its execution role.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create an Amazon S3 bucket policy that specifies the Lambda service as its principal and assign it to the Amazon S3 bucket.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Create an IAM role, attach the AmazonS3FullAccess managed policy to it, and assign the role to the Lambda function as its execution role.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec054af0-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>An organization is using Amazon CloudFront to ensure that its users experience low-latency access to its web application. The organization has identified a need to encrypt all traffic between users and CloudFront, and all traffic between CloudFront and the web application. How can these requirements be met? (Choose TWO)</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C,D</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec054af0-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec054af0-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Use AWS KMS to encrypt traffic between CloudFront and the web application.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Set the Origin Protocol Policy to 'HTTPS Only'.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Set the Origin's HTTP Port to 443.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Set the Viewer Protocol Policy to 'HTTPS Only' or 'Redirect HTTP to HTTPS'.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Enable the CloudFront option Restrict Viewer Access.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec054c44-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>An application is using Amazon DynamoDB as its data store, and should be able to read 100 items per second as strongly consistent reads. Each item is 5 KB in size. To what value should the table's provisioned read throughput be set?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec054c44-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec054c44-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>50 read capacity units.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>100 read capacity units.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>200 read capacity units.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>500 read capacity units.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec054d84-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>An application uses Lambda functions to extract metadata from files uploaded to an S3 bucket; the metadata is stored in Amazon DynamoDB. The application starts behaving unexpectedly, and the Developer wants to examine the logs of the Lambda function code for errors. Based on this system configuration, where would the Developer find the logs?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec054d84-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec054d84-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Amazon S3.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>AWS CloudTrail.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Amazon CloudWatch.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Amazon DynamoDB<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec054eba-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer is creating a Lambda function that will generate and export a file. The function requires 100 MB of temporary storage for temporary files while executing. These files will not be needed after the function is complete. How can the Developer MOST efficiently handle the temporary files?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec054eba-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec054eba-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Store the files in EBS and delete the files at the end of the Lambda function.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Copy the files to EFS and delete the files at the end of the Lambda function.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Store the files in the /tmp directory and delete the files at the end of the Lambda function.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Copy the files to an S3 bucket with a lifecycle policy to delete the files.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec054ffa-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer has developed a web application and wants to deploy it quickly on a Tomcat server on AWS. The Developer wants to avoid having to manage the underlying infrastructure. What is the easiest way to deploy the application, based on these requirements?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: B</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec054ffa-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec054ffa-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>AWS CloudFormation.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>AWS Elastic Beanstalk.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Amazon S3.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>AWS CodePipeline<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec05513a-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>An application runs on multiple EC2 instances behind an ELB. Where is the session data best written so that it can be served reliably across multiple requests?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec05513a-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec05513a-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Write data to Amazon ElastiCache.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Write data to Amazon Elastic Block Store.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Write data to Amazon EC2 Instance Store.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Write data to the root filesystem.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec055270-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A company is migrating from a monolithic architecture to a microservices-based architecture. The Developers need to refactor the application so that the many microservices can asynchronously communicate with each other without impacting performance. Use of which managed AWS services will enable asynchronous message passing? (Choose TWO)</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A,D</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec055270-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec055270-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Amazon SQS.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Amazon Cognito.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Amazon Kinesis.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Amazon SNS.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Amazon ElastiCache<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec0553b0-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>According to best practice, how should access keys be managed in AWS? (Choose TWO)</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: B,E</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec0553b0-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec0553b0-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Use the same access key in all applications for consistency.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Delete all access keys for the account root user.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Leave unused access keys in the account for tracking purposes.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Embed and encrypt access keys in code for continuous deployment.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use Amazon IAM roles instead of access keys where possible.<br></p>", "correct": true, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec0554f0-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>An application running on an Amazon Linux EC2 instance needs to manage the AWS infrastructure. How can the EC2 instance be configured to make AWS API calls securely?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec0554f0-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec0554f0-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Sign the AWS CLI command using the signature version 4 process.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Run the aws configure AWS CLI command and specify the access key id and secret access key.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Specify a role for the EC2 instance with the necessary privileges.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Pass the access key id and secret access key as parameters for each AWS CLI command.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec055630-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>An application needs to use the IP address of the client in its processing. The application has been moved into AWS and has been placed behind an Application Load Balancer (ALB). However, all the client IP addresses now appear to be the same. The application must maintain the ability to scale horizontally. Based on this scenario, what is the MOST cost-effective solution to this problem?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec055630-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec055630-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Remove the application from the ALB. Delete the ALB and change Amazon Route 53 to direct traffic to the instance running the application.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Remove the application from the ALB. Create a Classic Load Balancer in its place. Direct traffic to the application using the HTTP protocol.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Alter the application code to inspect the X-Forwarded-For header. Ensure that the code can work properly if a list of IP addresses is passed in the header.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Alter the application code to inspect a custom header. Alter the client code to pass the IP address in the custom header.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec05577a-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A development team is using AWS Elastic Beanstalk to deploy a two-tier application that consists of a load-balanced web tier and an Amazon RDS database tier in production. The team would like to separate the RDS instance from the Elastic Beanstalk. How can this be accomplished?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec05577a-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec05577a-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Use the Elastic Beanstalk CLI to disassociate the database.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use the AWS CLI to disassociate the database.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Change the deployment policy to disassociate the database.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Recreate a new Elastic Beanstalk environment without Amazon RDS.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec0558ba-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A company is using AWS CodePipeline to deliver one of its applications. The delivery pipeline is triggered by changes to the master branch of an AWS CodeCommit repository and uses AWS CodeBuild to implement the test and build stages of the process and AWS CodeDeploy to deploy the application. The pipeline has been operating successfully for several months and there have been no modifications. Following a recent change to the application's source code, AWS CodeDeploy has not deployed the updates application as expected. What are the possible causes? (Choose TWO)</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: B,C</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec0558ba-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec0558ba-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>The change was not made in the master branch of the AWS CodeCommit repository.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>One of the earlier stages in the pipeline failed and the pipeline has terminated.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>One of the Amazon EC2 instances in the company's AWS CodePipeline cluster is inactive.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>The AWS CodePipeline is incorrectly configured and is not executing AWS CodeDeploy.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>AWS CodePipeline does not have permissions to access AWS CodeCommit.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec055a18-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A social media company is using Amazon Cognito in order to synchronize profiles across different mobile devices, to enable end users to have a seamless experience. Which of the following configurations can be used to silently notify users whenever an update is available on all other devices?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec055a18-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec055a18-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Modify the user pool to include all the devices which keep them in sync.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use the SyncCallback interface to receive notifications on the application.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use an Amazon Cognito stream to analyze the data and push the notifications.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Use the push synchronization feature with the appropriate IAM role.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec055b58-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>An on-premises application is implemented using a Linux, Apache, MySQL and PHP (LAMP) stack. The Developer wants to run this application in AWS. Which of the following sets of AWS services can be used to run this stack?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec055b58-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec055b58-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Amazon API Gateway, Amazon S3.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>AWS Lambda, Amazon DynamoDB.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Amazon EC2, Amazon Aurora.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Amazon Cognito, Amazon RDS.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Amazon ECS, Amazon EBS.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec055ca2-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>An application displays a status dashboard. The status is updated by 1 KB messages from an SQS queue. Although the status changes infrequently, the Developer must minimize the time between the message arrival in the queue and the dashboard update. What technique provides the shortest delay in updating the dashboard?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec055ca2-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec055ca2-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Retrieve the messages from the queue using long polling every 20 seconds.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Reduce the size of the messages by compressing them before sending.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Retrieve the messages from the queue using short polling every 10 seconds.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Reduce the size of each message payload by sending it in two parts.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec055de2-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>An on-premises legacy application is caching data files locally and writing shared images to local disks. What is necessary to allow for horizontal scaling when migrating the application to AWS?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: B</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec055de2-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec055de2-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Modify the application to have both shared images and caching data written to Amazon EBS.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Modify the application to read and write cache data on Amazon S3, and also store shared images on S3.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Modify the application to use Amazon S3 for serving shared images; cache data can then be written to local disks.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Modify the application to read and write cache data on Amazon S3, while continuing to write shared images to local disks.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec055f2c-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer must trigger an AWS Lambda function based on the item lifecycle activity in an Amazon DynamoDB table. How can the Developer create the solution?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec055f2c-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec055f2c-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>A Developer must trigger an AWS Lambda function based on the item lifecycle activity in an Amazon DynamoDB table. How can the Developer create the solution?<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Enable a DynamoDB stream that publishes an SNS message. Trigger the Lambda function asynchronously from the SNS message.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Enable a DynamoDB stream, and trigger the Lambda function synchronously from the stream.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Enable a DynamoDB stream, and trigger the Lambda function asynchronously from the stream.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec056076-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>After installing the AWS CLI, a Developer tries to run the command awsconfigure but receives the following error:Error: aws: command not found. What is the most likely cause of this error?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec056076-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec056076-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>The aws executable is not in the PATH environment variable.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Access to the aws executable has been denied to the installer.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Incorrect AWS credentials were provided.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>The aws script does not have an executable file mode.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec0561ac-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>The Developer for a retail company must integrate a fraud detection solution into the order processing solution. The fraud detection solution takes between ten and thirty minutes to verify an order. At peak, the web site can receive one hundred orders per minute. What is the most scalable method to add the fraud detection solution to the order processing pipeline?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: B</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec0561ac-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec0561ac-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Add all new orders to an Amazon SQS queue. Configure a fleet of 10 EC2 instances spanning multiple AZs with the fraud detection solution installed on them to pull orders from this queue. Update the order with a pass or fails status.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Add all new orders to an SQS queue. Configure an Auto Scaling group that uses the queue depth metric as its unit of scale to launch a dynamically-sized fleet of EC2 instances spanning multiple AZs with the fraud detection solution installed on them to pull orders from this queue. Update the order with a pass or fails status.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Add all new orders to an Amazon Kinesis Stream. Subscribe a Lambda function to automatically read batches of records from the Kinesis Stream. The Lambda function includes the fraud detection software and will update the order with a pass or fail status.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Write all new orders to Amazon DynamoDB. Configure DynamoDB Streams to include all new orders. Subscribe a Lambda function to automatically read batches of records from the Kinesis Stream. The Lambda function includes the fraud detection software and will update the order with a pass or fail status.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec056314-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>When a Developer tries to run an AWS CodeBuild project, it raises an error because the length of all environment variables exceeds the limit for the combined maximum of characters. What is the recommended solution?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: D</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec056314-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec056314-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Add the export LC_ALL=\"en_US.utf8\" command to the pre_build section to ensure POSIX localization.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use Amazon Cognito to store key-value pairs for large numbers of environment variables.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Update the settings for the build project to use an Amazon S3 bucket for large numbers of environment variables.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use AWS Systems Manager Parameter Store to store large numbers of environment variables.<br></p>", "correct": true, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec056454-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A set of APIs are exposed to customers using the Amazon API Gateway. These APIs have caching enabled on the API Gateway. Customers have asked for an option to invalidate this cache for each of the APIs. What action can be taken to allow API customers to invalidate the API Cache?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec056454-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec056454-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Ask customers to use AWS credentials to call the InvalidateCache API.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Ask customers to invoke an AWS API endpoint which invalidates the cache.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Ask customers to pass an HTTP header called Cache-Control:max-age=0.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Ask customers to add a query string parameter called 'INVALIDATE_CACHE' when making an API call.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec056594-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer has been asked to build a real-time dashboard web application to visualize the key prefixes and storage size of objects in Amazon S3 buckets. Amazon DynamoDB will be used to store the Amazon S3 metadata. What is the optimal and MOST cost-effective design to ensure that the real-time dashboard is kept up to date with the state of the objects in the Amazon S3 buckets?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec056594-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec056594-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Use an Amazon CloudWatch event backed by an AWS Lambda function. Issue an Amazon S3 API call to get a list of all Amazon S3 objects and persist the metadata within DynamoDB. Have the web application poll the DynamoDBtable to reflect this change.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Use Amazon S3 Event Notification backed by a Lambda function to persist the metadata into DynamoDB. Have the web application poll the DynamoDB table to reflect this change.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Run a cron job within an Amazon EC2 instance to list all objects within Amazon S3 and persist the metadata into DynamoDB. Have the web application poll the DynamoDB table to reflect this change.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create a new Amazon EMR cluster to get all the metadata about Amazon S3 objects; persist the metadata into DynamoDB. Have the web application poll the DynamoDB table to reflect this change.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec0566fc-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer must repeatedly and consistently deploy a serverless RESTful API on AWS. Which techniques will work? (Choose TWO)</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C,D</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec0566fc-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec0566fc-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Define a Swagger file. Use AWS Elastic Beanstalk to deploy the Swagger file.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Define a Swagger file. Use AWS CodeDeploy to deploy the Swagger file.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Deploy a SAM template with an inline Swagger definition.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Define a Swagger file. Deploy a SAM template that references the Swagger file.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Define an inline Swagger definition in a Lambda function. Invoke the Lambda function.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec05685a-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>An existing serverless application processes uploaded image files. The process currently uses a single Lambda function that takes an image file, performs the processing, and stores the file in Amazon S3. Users of the application now require thumbnail generation of the images. Users want to avoid any impact to the time it takes to perform the image uploads. How can thumbnail generation be added to the application, meeting user requirements while minimizing changes to existing code?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec05685a-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec05685a-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Change the existing Lambda function handling the uploads to create thumbnails at the time of upload. Have the function store both the image and thumbnail in Amazon S3.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Create a second Lambda function that handles thumbnail generation and storage. Change the existing Lambda function to invoke it asynchronously.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create an S3 event notification with a Lambda function destination. Create a new Lambda function to generate and store thumbnails.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Create an S3 event notification to an SQS Queue. Create a scheduled Lambda function that processes the queue, and generates and stores thumbnails.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec0569b8-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A company is using Amazon API Gateway to manage access to a set of microservices implemented as AWS Lambda functions. Following a bug report, the company makes a minor breaking change to one of the APIs. In order to avoid impacting existing clients when the new API is deployed, the company wants to allow clients six months to migrate from v1 to v2. Which approach should the Developer use to handle this change?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec0569b8-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec0569b8-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Update the underlying Lambda function and provide clients with the new Lambda invocation URL.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use API Gateway to automatically propagate the change to clients, specifying 180 days in the phased deployment parameter.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use API Gateway to deploy a new stage named v2 to the API and provide users with its URL.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Update the underlying Lambda function, create an Amazon CloudFront distribution with the updated Lambda function as its origin.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec056b16-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A company developed a set of APIs that are being served through the Amazon API Gateway. The API calls need to be authenticated based on OpenID identity providers such as Amazon or Facebook. The APIs should allow access based on a custom authorization model. Which is the simplest and MOST secure design to use to build an authentication and authorization model for the APIs?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: A</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec056b16-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec056b16-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Use Amazon Cognito user pools and a custom authorizer to authenticate and authorize users based on JSON Web Tokens.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Build a OpenID token broker with Amazon and Facebook. Users will authenticate with these identify providers and pass the JSON Web Token to the API to authenticate each API call.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Store user credentials in Amazon DynamoDB and have the application retrieve temporary credentials from AWS STS. Make API calls by passing user credentials to the APIs for authentication and authorization.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Use Amazon RDS to store user credentials and pass them to the APIs for authentications and authorization.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec056c74-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>Where should an Elastic Beanstalk configuration file named healthcheckur1.config be placed in the application source bundle?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: D</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec056c74-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec056c74-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>In the root of the application.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>In the bin folder.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>In healthcheckur1.config.ebextension under root.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>In the .ebextensions folder.<br></p>", "correct": true, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec056dbe-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A Developer has implemented a Lambda function that needs to add new customers to an RDS database that is expected to run hundreds of times per hour. The Lambda function is configured to use 512MB of RAM and is based on the following pseudo code. After testing the Lambda function, the Developer notices that the Lambda execution time is much longer than expected. What should the Developer do to improve performance? [Question 385](images/question385.jpg)</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: C</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec056dbe-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec056dbe-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Increase the amount of RAM allocated to the Lambda function, which will increase the number of threads the Lambda can use.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Increase the size of the RDS database to allow for an increased number of database connections each hour.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Move the database connection and close statement out of the handler. Place the connection in the global space.<br></p>", "correct": true, "feedback": ""}, {"choice": "<p>Replace RDS wit Amazon DynamoDB to implement control over the number of writes per second.<br></p>", "correct": false, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec056f12-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>A static website is hosted in an Amazon S3 bucket. Several HTML pages on the site use JavaScript to download images from another Amazon S3 bucket. These images are not displayed when users browse the site. What is the possible cause for the issue?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: D</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec056f12-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec056f12-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>The referenced Amazon S3 bucket is in another region.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>The images must be stored in the same Amazon S3 bucket.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Port 80 must be opened on the security group in which the Amazon S3 bucket is located.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Cross Origin Resource Sharing must be enabled on the Amazon S3 bucket.<br></p>", "correct": true, "feedback": ""}]}], "topic_name": "Unknown"},
      {"question_id": "#ec057052-cae0-11ee-8b0b-6ab9697dea9c", "topic_id": 1, "course_id": 1, "case_study_id": "null", "lab_id": 0, "question_text": "<p>Amazon S3 has the following structure: S3://BUCKET/FOLDERNAME/FILENAME.zip Which S3 best practice would optimize performance with thousands of PUT request each second to a single bucket?</p>", "mark": 1, "is_partially_correct": false, "question_type": "1", "difficulty_level": "0", "general_feedback": ["<p>Correct Answer: D</p>"], "is_active": true, "answer_list": [{"question_answer_id": "ec057052-cae0-11ee-8b0b-6ab9697dea9c", "question_id": "#ec057052-cae0-11ee-8b0b-6ab9697dea9c", "answers": [{"choice": "<p>Prefix folder names with user id; for example, s3://BUCKET/2013-FOLDERNAME/FILENAME.zip.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Prefix file names with timestamps; for example, s3://BUCKET/FOLDERNAME/2013-26-05-15-00-00-FILENAME.zip.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Prefix file names with random hex hashes; for example, s3://BUCKET/FOLDERNAME/23a6-FILENAME.zip.<br></p>", "correct": false, "feedback": ""}, {"choice": "<p>Prefix folder names with random hex hashes; for example, s3://BUCKET/23a6-FOLDERNAME/FILENAME.zip.<br></p>", "correct": true, "feedback": ""}]}], "topic_name": "Unknown"}]
  }